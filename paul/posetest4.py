import cv2
import numpy
import math
from enum import Enum
import sys

# load constants from external file
constants = {}
s = exec(open(sys.argv[1], 'r').read(), constants)

_hsv_threshold_hue = constants['hsv_threshold_hue']
_hsv_threshold_saturation = constants['hsv_threshold_saturation']
_hsv_threshold_value = constants['hsv_threshold_value']

class GripPipeline:
    """
    An OpenCV pipeline generated by GRIP.
    """
    
    def __init__(self):
        """initializes all values to presets or None if need to be set
        """

        self.__hsv_threshold_hue = constants['hsv_threshold_hue']
        self.__hsv_threshold_saturation = constants['hsv_threshold_saturation']
        self.__hsv_threshold_value = constants['hsv_threshold_value']


        self.hsv_threshold_output = None


    def process(self, source0):
        """
        Runs the pipeline and sets all outputs to new values.
        """
        # Step HSV_Threshold0:
        self.__hsv_threshold_input = source0
        (self.hsv_threshold_output) = self.__hsv_threshold(self.__hsv_threshold_input, self.__hsv_threshold_hue, self.__hsv_threshold_saturation, self.__hsv_threshold_value)


    @staticmethod
    def __hsv_threshold(input, hue, sat, val):
        """Segment an image based on hue, saturation, and value ranges.
        Args:
            input: A BGR numpy.ndarray.
            hue: A list of two numbers the are the min and max hue.
            sat: A list of two numbers the are the min and max saturation.
            lum: A list of two numbers the are the min and max value.
        Returns:
            A black and white numpy.ndarray.
        """
        out = cv2.cvtColor(input, cv2.COLOR_BGR2HSV)
        return cv2.inRange(out, (hue[0], sat[0], val[0]),  (hue[1], sat[1], val[1]))

import os
import numpy as np
import sys

# parameters of the camera which can be determined using calibrate.py from OpenCV
cam_mtrx = constants['cam_mtrx']
distorts = constants['distorts']

# location of the target points, in world space, in order
world_pts = [
        (3.313, 4.824),
        (1.337, 5.325),
        (0, 0),
        (1.936, -0.501),
        (13.290, 5.325),
        (11.314, 4.824),
        (12.691, -0.501),
        (14.627, 0),
]

# stolen from somewhere, draws a cube given perspective-transformed points
def draw_cube(img, corner, imgpts):
    imgpts = np.int32(imgpts).reshape(-1,2)
    # draw ground floor in green
    img = cv2.drawContours(img, [imgpts[:4]],-1,(0,255,0),-3)
    # draw pillars in blue color
    for i,j in zip(range(4),range(4,8)):
        img = cv2.line(img, tuple(imgpts[i]), tuple(imgpts[j]),(255),3)
    # draw top layer in red color
    img = cv2.drawContours(img, [imgpts[4:]],-1,(0,0,255),3)
    return img

cube = np.float32([[0,0,0], [0,3,0], [3,3,0], [3,0,0],
                   [0,0,-3],[0,3,-3],[3,3,-3],[3,0,-3] ])


DEV = int(sys.argv[2])
USE_CAP = True
world_pts = np.float32([(x, -y, 0) for x, y in world_pts])
print(world_pts)
print(cam_mtrx)
if USE_CAP:
    cap = cv2.VideoCapture(DEV)
    print('Got cap')
    exposure = constants['exposure'] if len(sys.argv) < 4 else int(sys.argv[3])
    os.system('v4l2-ctl -d /dev/video{} -c exposure_auto=1 -c white_balance_temperature_auto=0 -c exposure_absolute={}'.format(DEV, exposure))
    os.system('v4l2-ctl -d /dev/video{} -c focus_auto=0'.format(DEV))
    os.system('v4l2-ctl -d /dev/video{} -c focus_absolute=0'.format(DEV))
    res_x, res_y = constants.get('resolution', (640, 480))
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, res_x)
    #cap.set(cv2.CAP_PROP_FRAME_WIDTH, 864)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, res_y)

# the GRIP pipeline is pretty trivial and just does the first level of HSV filtering
pipeline = GripPipeline()
targetColor = constants['targetColor']
lab_factors = 2, 1, 1
g_rot = np.float32([[0, 0, 0]]).T
g_pos = np.float32([[0, 0, 0]]).T
g_rot2 = np.float32([[0, 0, 0]]).T
g_pos2 = np.float32([[0, 0, 0]]).T
kernel = np.ones((5, 5), np.uint8)
from dataclasses import dataclass
import typing
@dataclass
            #return Rect(area=cv2.contourArea(lf), points=lf, refined=np.bool_(pointsRefined), center=(centerx, centery), tilt=ang)
class Rect:
    area: float
    points: typing.Any
    refined: np.ndarray
    center: tuple
    tilt: float
import itertools
#import rspnp
def main_loop():
    saves_left = 0
    while True:
        rv, fr = cap.read()
        if not rv: break
        #fr = cv2.imread('Target2.png')#.svg.png')

        fr_lab = cv2.cvtColor(fr, cv2.COLOR_BGR2LAB)
        # convert frame to LAB color space
        channels = cv2.split(fr_lab.astype('int16'))

        # create image of how close each pixel is to a certain color
        greenscale = np.zeros(fr.shape[:-1], 'int16')
        for tr, ch, fac in zip(targetColor, channels, lab_factors):
            greenscale += np.absolute(ch - tr) // fac
        greenscale = 255 - np.clip((greenscale), 0, 255).astype('uint8')
        cv2.imshow('greenscale', greenscale)
        #pipeline.process(fr)
        #op = pipeline.hsv_threshold_output

        
        hsv_frame = cv2.cvtColor(fr, cv2.COLOR_BGR2HSV)
        op = cv2.inRange(hsv_frame, (_hsv_threshold_hue[0], _hsv_threshold_saturation[0], _hsv_threshold_value[0]),  (_hsv_threshold_hue[1], _hsv_threshold_saturation[1], _hsv_threshold_value[1]))

        o8 = op.astype('uint8') * 255
        corners = cv2.cornerHarris(np.float32(greenscale), 2, 3, 0.03)

        # version of corners image suitable for being displayed
        cm = corners.copy()
        cm[cm < 0] = 0
        cm = cv2.cvtColor((cm / 65536).astype(np.float32),cv2.COLOR_GRAY2RGB)
        
        # erode and dilate to reduce noise in thresholded image
        eroded_hsv_1 = cv2.dilate(cv2.erode(op, kernel, iterations=1), kernel, iterations=1)#.astype(np.bool_)

        # find contours
        contours1, hier1 = cv2.findContours(eroded_hsv_1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
        approxes = [cv2.approxPolyDP(x, 0.01 * cv2.arcLength(x, True), True) for x in contours1]

        a = False
        pts1 = []
        prevArea = 0
        rectangles = []
        ## Find contour edges, then find their intersections to find approximate corner locations
        # iterate over contours, large to small
        for area, loop in sorted(((cv2.contourArea(x), x) for x in approxes), key=lambda x: x[0], reverse=True):
            if len(loop) > 8: continue
            if area < prevArea / 2: continue
            prevArea = area

            angles = np.zeros(len(loop), dtype='float32')
            ll = len(loop)
            # find angles of each corner and eliminate angles that are too straight
            for i, cur in enumerate(loop):
                prev = loop[(i-1)%ll][0]
                nex = loop[(i+1)%ll][0]
                cur = cur[0]
                angles[i] = (math.atan2(cur[1] - prev[1], cur[0] - prev[0]) - math.atan2(cur[1] - nex[1], cur[0] - nex[0])) % math.pi
            sp = [x[0] for i, x in enumerate(loop) if angles[i] < math.pi * .85]
            if len(sp) < 4: continue

            # Order edges by long, short, long, short, so that each consecutive pair has an intersection
            pairs = [(sp[i], sp[(i+1)%len(sp)]) for i in range(len(sp))]
            relevantLines = list(sorted(pairs, key=lambda x: ((x[0][0] - x[1][0]) ** 2 + (x[0][1] - x[1][1]) ** 2), reverse=True))[:4]
            order = relevantLines[0], relevantLines[2], relevantLines[1], relevantLines[3]
            nr = []
            for i, cur in enumerate(order):
                nex = order[(i+1)%4]
                (x1, y1), (x2, y2) = cur
                (x3, y3), (x4, y4) = nex
                # find intersections
                try:
                    res = np.linalg.solve(np.array([
                        [x2 - x1, 0, -1, 0],
                        [y2 - y1, 0, 0, -1],
                        [0, x4 - x3, -1, 0],
                        [0, y4 - y3, 0, -1]]), np.array([[-x1, -y1, -x3, -y3]]).T)
                except np.linalg.LinAlgError:
                    # if lines are parallel, ignore
                    continue
                nr.append(res[2:4,0])
                #pts1.append(res[2:4,0])
            rectangles.append(nr)


        # Look for Harris corners in the areas selected by edge intersections
        fc = []
        onscreen_fc = []
        tt = fr.copy()
        fmax = corners.max()
        BOX_SIZE=7
        def refine_point(x, y):
            if x < -BOX_SIZE /2  or x > fr.shape[1] + BOX_SIZE / 2 or y < -BOX_SIZE / 2 or y > fr.shape[0] + BOX_SIZE / 2:
                return (x, y), False
            ix, iy = int(x), int(y)
            # find coords of top-left corner
            mx, my = max(ix - BOX_SIZE, 0), max(iy - BOX_SIZE, 0)
            region = corners[my:iy+BOX_SIZE,mx:ix+BOX_SIZE]
            masked = (region > .0085 * fmax)#.002 * fmax)
            # update debug image
            #tt[my:iy+BOX_SIZE,mx:ix+BOX_SIZE,0] = masked * 255
            #tt[my:iy+BOX_SIZE,mx:ix+BOX_SIZE,1] = masked * 255
            #tt[my:iy+BOX_SIZE,mx:ix+BOX_SIZE,2] = masked * 255
            ret, labels, stats, centroids = cv2.connectedComponentsWithStats(masked.astype('uint8'))
            if len(centroids) <= 1:
                #if x < 0 or x > fr.shape[1] or y < 0 or y > fr.shape[0]:
                return (x, y), False
                #fc.append((x, y))
                cv2.rectangle(cm, (ix - BOX_SIZE, iy - BOX_SIZE), (ix + BOX_SIZE, iy + BOX_SIZE), (0.0, 0.0, 1.0))
            cv2.rectangle(cm, (ix - BOX_SIZE, iy - BOX_SIZE), (ix + BOX_SIZE, iy + BOX_SIZE), (0.0, 1.0, 0.0))
            rc1 = np.log(region - (region.min() - 1))
            def key(x):
                i, (stat, centroid) = x
                rc = rc1.copy()
                rc[labels != (i + 1)] = 0
                return rc.sum()
            # get connected component with the highest total Harris corner value
            i, (st, (cx, cy)) = max(enumerate(zip(stats[1:], centroids[1:])), key=key)
            cv2.circle(tt, (int(cx + mx), int(cy + my)), 1, (0, 0, 255), -1)
            return (cx + mx, cy + my), True

        def create_Rect(l):
            points, pointsRefined = zip(*l)
            pairs = [(points[i], points[(i+1)%len(points)]) for i in range(len(points))]
            relevantLines = list(sorted(pairs, key=lambda x: ((x[0][0] - x[1][0]) ** 2 + (x[0][1] - x[1][1]) ** 2), reverse=True))
            #print(len(relevantLines))
            def ap(a, b):
                return (a[0] + b[0]) / 2, (a[1] + b[1]) / 2
            x1, y1 = ap(*relevantLines[2])
            x2, y2 = ap(*relevantLines[3])
            ang = math.atan2(y1 - y2, x2 - x1) % math.pi
            cv2.putText(fr,'{:.2f}'.format(ang),(int(x1 + x2) // 2,int(y1 + y2) // 2), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),1,cv2.LINE_AA)
            #print(ang)
            centerx, centery = np.mean(np.float32(points), axis=0)
            def key(r):
                (x, y), legit = r
                dx, dy = x - centerx, y - centery
                return math.atan2(-dy, dx) % (2 * math.pi)
            points, pointsRefined = zip(*sorted(l, key=key))
            lf = np.float32(points)
            return Rect(area=cv2.contourArea(lf), points=lf, refined=np.bool_(pointsRefined), center=np.float32([centerx, centery]), tilt=ang)
        refined_rects = [create_Rect([refine_point(x, y) for x, y in rect]) for rect in rectangles if len(rect) == 4]
        
        OFFS = 14.5 * math.pi / 180
        pairs = []
        ss = list(sorted(refined_rects, key=lambda x: x.area, reverse=True))
        i = 0
        while i < len(ss):
            rect = ss[i]
            r_ang = (rect.tilt - math.pi / 2 + OFFS)
            l_ang = (rect.tilt + math.pi / 2 - OFFS)
            na = rect.tilt - math.pi / 2
            def coord_change(pt, v1, v2):
                return np.linalg.solve(np.float32(
                    [[v1[0], v2[0]],
                     [v1[1], v2[1]]]), np.float32(pt).T).T
            def gp(x, y):
                return (x, y), (y, -x)
            right = gp(math.cos(r_ang), math.sin(r_ang))
            left = gp(math.cos(l_ang), math.sin(l_ang))
            nvec = gp(math.cos(na), math.sin(na))
            cv2.putText(fr,'{:.02f} {:.02f} {:.02f}'.format(rect.tilt, nvec[0][0], nvec[0][1]),tuple(map(int, rect.center)), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),1,cv2.LINE_AA)
            cc = np.float32(nvec[1]) * (20, -20) + rect.center
            try:
                cv2.line(fr, (int(rect.center[0]), int(rect.center[1])), (int(cc[0]), int(cc[1])), (255, 0, 255), 2, cv2.LINE_AA)
            except OverflowError:
                pass
            def key(nr):
                pt = nr.center - rect.center
                x, y = coord_change(pt, *nvec)
                if abs(nr.tilt - rect.tilt) < 10 / 180 * math.pi: return float('inf')
                if x < 0 != nr.tilt < rect.tilt: return float('inf')
                x1, y1 = coord_change(pt, *(left if x < 0 else right))
                return 10 * (y1 ** 2) + x1 ** 2
            def ok_y(nr):
                x, y = coord_change(nr.center, *nvec)
                x1, y1 = coord_change(nr.center - rect.center, *left)
                x2, y2 = coord_change(nr.center - rect.center, *right)
                return (abs(y1) * 8 < abs(x1)) if x < 0 else (abs(y2) * 8 < abs(x2))

            try:
                idx, mate = min(((i, x) for i, x in enumerate(ss) if rect != x and ok_y(x) and rect.area / math.sqrt(2) < x.area < rect.area * math.sqrt(2)), key=lambda x: key(x[1]))
            except ValueError:
                cv2.drawMarker(fr, tuple(map(int, rect.center)), (0, 0, 255))
                pass
            else:
                pairs.append((rect, mate))
                del ss[idx]
            i += 1


        for n1, n2 in pairs:
            c1 = tuple(np.int32(n1.center))
            c2 = tuple(np.int32(n2.center))
            print(c1, c2)
            cv2.line(fr, c1, c2, (0, 0, 255), 2, cv2.LINE_AA)
            #cv2.drawMarker(fr, c2, (0, 255, 0))
            
        c_exact = []
        if any(onscreen_fc):
            criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)
            # refine corners to sub-pixel level
            c_exact1 = cv2.cornerSubPix(greenscale, np.float32([x for i, x in enumerate(fc) if onscreen_fc[i]]), (5, 5), (-1, -1), criteria)
            #if len(c_exact1) < len(onscreen_fc): continue
            c_exact = []
            j = 0
            for i, v in enumerate(onscreen_fc):
                if v:
                    c_exact.append((c_exact1[j], True))
                    j += 1
                else:
                    c_exact.append((fc[i], False))
            for (x, y), legit in c_exact:
                try:
                    cv2.circle(fr, (int(x), int(y)), 3, (255, 64, 64), 1)
                except OverflowError:
                    pass
            #for i, (x, y, z) in enumerate(world_pts):
            #    cv2.putText(fr,str(i),(int(x*5),int(y*5)+50), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255),1,cv2.LINE_AA)
            
            ## Sort points. First split left and right rectangle, then sort counterclockwise by angle to the center
            if sum(onscreen_fc) > 4 and len(onscreen_fc) == 8:
                h = list(sorted(c_exact, key=lambda x: x[0][0]))
                left = h[:4]
                right = h[4:]
                pts = []
                for rect in left, right:
                    centerx, centery = sum(x[0][0] for x in rect) / len(rect), sum(x[0][1] for x in rect) / len(rect)
                    def key(r):
                        (x, y), legit = r
                        dx, dy = x - centerx, y - centery
                        return math.atan2(-dy, dx) % (2 * math.pi)
                    l = list(sorted(rect, key=key))
                    #for i, l1 in enumerate(l):
                    #    l2 = l[(i+1)%4]
                    #    cv2.line(fr, tuple(l1), tuple(l2), (0, 0, 255), 1, cv2.LINE_AA)
                    pts += l
                for i, ((x, y), legit) in enumerate(pts):
                    cv2.putText(fr,str(i),(int(x),int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255),1,cv2.LINE_AA)
                pts_to_solve = np.bool_(onscreen_fc)
                fpts = np.float32([x[0] for x in pts])
                pts_f = fpts[pts_to_solve]
                world_pts_f = world_pts[pts_to_solve]
                global g_rot, g_pos, g_rot2, g_pos2
                if not ((g_rot == 0).all() and (g_pos == 0).all()):
                    retval2_, rvecs, tvecs, inliers_ = cv2.solvePnPRansac(world_pts_f, pts_f, cam_mtrx, distorts, g_rot, g_pos, useExtrinsicGuess=True)#, flags=cv2.SOLVEPNP_EPNP)
                else:
                    retval2_, rvecs, tvecs, inliers_ = cv2.solvePnPRansac(world_pts_f, pts_f, cam_mtrx, distorts)#, flags=cv2.SOLVEPNP_EPNP)
                #print(world_pts_f)
                #print(pts_f)
                #if not ((g_rot == 0).all() and (g_pos == 0).all()):
                #    retval2, rvecs1, tvecs1, rvecs2, tvecs2 = rspnp.solve_rspnp(world_pts_f, pts_f, cam_mtrx, distorts, rspnp.SHUTTER.VERTICAL, [0, 480], rvec1=g_rot2, tvec1=g_pos2, useExtrinsicGuess=True)#, flags=cv2.SOLVEPNP_EPNP)
                #else:
                #    retval2, rvecs1, tvecs1, rvecs2, tvecs2 = rspnp.solve_rspnp(world_pts_f, pts_f, cam_mtrx, distorts, rspnp.SHUTTER.VERTICAL, [0, 480])#, flags=cv2.SOLVEPNP_EPNP)
                #rvecs_ = (rvecs1 + rvecs2) / 2
                #tvecs_ = (tvecs1 + tvecs2) / 2
                print(np.stack((rvecs[:,0], tvecs[:,0]), axis=1))
                #print(np.stack((rvecs_[:,0], tvecs_[:,0]), axis=1))
                #print(rvecs, tvecs, rvecs2, tvecs2)
                inliers = np.expand_dims(np.arange(8), axis=1)
                #retval2, rvecs, tvecs, = cv2.solvePnP(world_pts, pts, cam_mtrx, distorts)#, flags=cv2.SOLVEPNP_EPNP)
                cv2.putText(fr,'I: {}/{}'.format(len(inliers) if inliers is not None else 'X', len(pts_f)),(530, 50), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255) if inliers is not None and len(inliers) == len(pts_f) else (0,0,255),1,cv2.LINE_AA)
                if inliers is not None:
                    o = set(range(len(pts_f))) - set(inliers[:,0])
                    for idx in o:
                        x, y = pts_f[idx]
                        ix, iy = int(x), int(y)
                        #cv2.line(fr, (ix - 5, iy - 5), (ix + 5, iy + 5), (0, 0, 255), 1, cv2.LINE_AA)
                        #cv2.line(fr, (ix - 5, iy + 5), (ix + 5, iy - 5), (0, 0, 255), 1, cv2.LINE_AA)
                        cv2.circle(fr, (ix, iy), 3, (0, 0, 255), 1)

                    centerp = np.float32([14.627/2, -5.325/2, 0])
                    g_rot = rvecs
                    g_pos = tvecs
                    #g_rot2 = rvecs_
                    #g_pos2 = tvecs_

                    # Project cube according to perspective and display
                    qb = cube + centerp
                    #print(qb)
                    imgpts, jac = cv2.projectPoints(qb, rvecs, tvecs, cam_mtrx, distorts)
                    #print(cam_mtrx)
                    #print(distorts)
                    #print(imgpts)
                    if not any(abs(x) > 1500 for x in imgpts.flatten()):
                        fr = draw_cube(fr, None, imgpts)

                    #pts2, jac = cv2.projectPoints(world_pts, rvecs, tvecs, cam_mtrx, distorts)
                    #for x, y in np.int32(pts2).reshape(-1, 2):
                    #    cv2.circle(fr, (x, y), 2, (255, 255, 255), -1)
            else:
                cv2.putText(fr,'C: {}'.format(len(c_exact)),(550, 25), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255),1,cv2.LINE_AA)



        #cv2.imshow('corners', corners)
        cv2.imshow('corners', cm)
        cv2.imshow('dsst', op)
        cv2.imshow('f1', fr)
        if saves_left > 0:
            cv2.imwrite('frame_{}.png'.format(10 - saves_left), fr)
            saves_left -= 1
        #cv2.imshow('bc', zer)
        key = cv2.waitKey(1) & 0xff
        if key == 27: break
        if key == ord('s') and saves_left == 0:
            saves_left = 10
    cv2.destroyAllWindows()
import threading
t = threading.Thread(target=main_loop)

from direct.showbase.ShowBase import ShowBase
from direct.task import Task
def invertPerspective(rvecs, tvecs):
        rod, jac = cv2.Rodrigues(rvecs)
        mat = np.append(np.append(rod, tvecs, axis=1), np.float32([[0, 0, 0, 1]]), axis=0)
        m2 = np.linalg.inv(mat)[:-1]
        tr2 = m2[:,3]
        rot2_rod = m2[:,:3]
        rot2, jac = cv2.Rodrigues(rot2_rod)
        return rot2, tr2

class MyApp(ShowBase):
 
    def __init__(self):
        ShowBase.__init__(self)
        #self.scene = self.loader.loadModel("models/environment")
        self.scene = self.loader.loadModel("Target.egg")
        self.scene.setHpr(0, 90, 0)
        self.scene.reparentTo(self.render)
        #self.sph = self.loader.loadModel("smiley.egg")
        self.cam_ind = self.loader.loadModel("camera.egg")
        self.cam_ind.reparentTo(self.render)
        self.cam_ind.setScale(2.5)
        self.cam_ind.setColorScale(1.0, 0.6, 0.6, 1.0)
        self.cam_ind2 = self.loader.loadModel("camera.egg")
        self.cam_ind2.reparentTo(self.render)
        self.cam_ind2.setScale(2.5)
        self.cam_ind2.setColorScale(0.6, 0.6, 1.0, 1.0)
        self.useTrackball()
        print(self.trackball.node().getPos())
        self.scene.setPos(0, 0, -.254)
        self.taskMgr.add(self.updateTask, "update")
        self.camLens.setFov(60)
    def updateTask(self, t):
        # Find inverse of perspective transform (get "camera moves" perspective)
        persp1 = invertPerspective(g_rot, g_pos)
        #persp2 =invertPerspective(g_rot2, g_pos2)
        #rod, jac = cv2.Rodrigues(g_rot)
        #mat = np.append(np.append(rod, g_pos, axis=1), np.float32([[0, 0, 0, 1]]), axis=0)
        #m2 = np.linalg.inv(mat)[:-1]
        #tr2 = m2[:,3]
        #rot2_rod = m2[:,:3]
        #rot2, jac = cv2.Rodrigues(rot2_rod)
        # 2.54 cm/inch
        for cm, (rot2, tr2) in ((self.cam_ind, persp1),):# (self.cam_ind2, persp2)):
            if np.isnan(rot2).any() or np.isnan(tr2).any(): continue
            x, y, z = tr2 * 2.54 #g_pos[:,0] * 2.54
            rx, ry, rz = rot2[:,0] * (180 / math.pi)
            #print(id(cm), x, y, z)
            cm.setPos(x, z, -y)
            cm.setHpr(-ry, rx, rz)#-rz, -rz)#rx, -rz)
        return Task.cont

if __name__ == '__main__':
    main_loop()
    #app = MyApp()
    #t.start()
    #app.run()
